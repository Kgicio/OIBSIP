{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5f33d1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Isolation Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     56864\n",
      "           1       0.09      0.55      0.16        98\n",
      "\n",
      "    accuracy                           0.99     56962\n",
      "   macro avg       0.55      0.77      0.58     56962\n",
      "weighted avg       1.00      0.99      0.99     56962\n",
      "\n",
      "Isolation Forest Confusion Matrix:\n",
      " [[56334   530]\n",
      " [   44    54]]\n",
      "Isolation Forest AUPRC: 0.0517\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56864\n",
      "           1       0.06      0.92      0.12        98\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.53      0.95      0.55     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[55499  1365]\n",
      " [    8    90]]\n",
      "Logistic Regression AUPRC: 0.7206\n",
      "Logistic Regression model saved for real-time predictions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "from multiprocessing import Process\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:/Users/User/fraud_detection_project/data/creditcard.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Scale 'Amount' and 'Time' features\n",
    "scaler = StandardScaler()\n",
    "data[['Amount', 'Time']] = scaler.fit_transform(data[['Amount', 'Time']])\n",
    "\n",
    "# Feature Engineering: Create new features or transform existing features\n",
    "data['Amount_log'] = np.log1p(data['Amount'])\n",
    "data['Time_hour'] = data['Time'] // 3600 % 24\n",
    "data = data.drop(['Time'], axis=1)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Anomaly detection using Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "iso_forest.fit(X_train)\n",
    "anomalies = iso_forest.predict(X_test)\n",
    "\n",
    "# Convert anomalies to binary classification (1: anomaly, 0: normal)\n",
    "anomalies = [1 if x == -1 else 0 for x in anomalies]\n",
    "report_iso_forest = classification_report(y_test, anomalies)\n",
    "conf_matrix_iso_forest = confusion_matrix(y_test, anomalies)\n",
    "print(\"Isolation Forest Classification Report:\\n\", report_iso_forest)\n",
    "print(\"Isolation Forest Confusion Matrix:\\n\", conf_matrix_iso_forest)\n",
    "\n",
    "# Calculate AUPRC for Isolation Forest\n",
    "auprc_iso_forest = average_precision_score(y_test, anomalies)\n",
    "print(f\"Isolation Forest AUPRC: {auprc_iso_forest:.4f}\")\n",
    "\n",
    "# Initialize and train the Logistic Regression model with class weights\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "report_log_reg = classification_report(y_test, y_pred_log_reg)\n",
    "conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
    "print(\"Logistic Regression Classification Report:\\n\", report_log_reg)\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", conf_matrix_log_reg)\n",
    "\n",
    "# Calculate AUPRC for Logistic Regression\n",
    "auprc_log_reg = average_precision_score(y_test, log_reg.predict_proba(X_test)[:, 1])\n",
    "print(f\"Logistic Regression AUPRC: {auprc_log_reg:.4f}\")\n",
    "\n",
    "# Save the Logistic Regression model for real-time predictions\n",
    "joblib.dump(log_reg, 'log_reg_model.pkl')\n",
    "print(\"Logistic Regression model saved for real-time predictions.\")\n",
    "\n",
    "# Kafka Producer for Real-time Monitoring (Simulating streaming data)\n",
    "def kafka_producer():\n",
    "    producer = KafkaProducer(bootstrap_servers='localhost:9092', value_serializer=lambda x: json.dumps(x).encode('utf-8'))\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data.iloc[i:i+batch_size]\n",
    "        for _, row in batch.iterrows():\n",
    "            producer.send('transaction_topic', value=row.to_dict())\n",
    "        time.sleep(0.1)  # Simulate the delay between batches\n",
    "    print(\"Kafka Producer finished sending data.\")\n",
    "\n",
    "# Kafka Consumer for Real-time Predictions\n",
    "def kafka_consumer():\n",
    "    consumer = KafkaConsumer('transaction_topic', bootstrap_servers='localhost:9092', value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
    "    model = joblib.load('log_reg_model.pkl')\n",
    "    batch_size = 100\n",
    "    transactions = []\n",
    "    for message in consumer:\n",
    "        transaction = pd.DataFrame([message.value])\n",
    "        transactions.append(transaction)\n",
    "        if len(transactions) >= batch_size:\n",
    "            batch = pd.concat(transactions)\n",
    "            batch['Amount_log'] = np.log1p(batch['Amount'])\n",
    "            batch['Time_hour'] = batch['Time'] // 3600 % 24\n",
    "            batch = batch.drop(['Time'], axis=1)\n",
    "            predictions = model.predict(batch.drop('Class', axis=1))\n",
    "            for i, prediction in enumerate(predictions):\n",
    "                if prediction == 1:\n",
    "                    print(f\"Fraudulent transaction detected: {batch.iloc[i].to_dict()}\")\n",
    "            transactions = []\n",
    "    print(\"Kafka Consumer finished processing data.\")\n",
    "\n",
    "# Start Kafka Producer and Consumer\n",
    "if __name__ == \"__main__\":\n",
    "    producer_process = Process(target=kafka_producer)\n",
    "    consumer_process = Process(target=kafka_consumer)\n",
    "    producer_process.start()\n",
    "    consumer_process.start()\n",
    "    producer_process.join()\n",
    "    consumer_process.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a210f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
